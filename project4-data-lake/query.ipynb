{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Checking result  - Data Lake on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Make sure that your AWS credentials are loaded as env vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "#Normally this file should be in ~/.aws/credentials\n",
    "config.read_file(open('dl.cfg'))\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "S3_BUCKET_OUTPUT = config.get(\"S3\", \"S3_BUCKET_OUTPUT\")\n",
    "output_data = \"s3a://{}/\".format(S3_BUCKET_OUTPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Create spark session with hadoop-aws package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Load data from S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## songs_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_df = spark.read.parquet(output_data + 'songs_table/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      "\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|           song_id|               title| duration|year|         artist_id|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|SOKTJDS12AF72A25E5|Drown In My Own T...|  192.522|   0|ARA23XO1187B9AF18F|\n",
      "|SOEKAZG12AB018837E|I'll Slap Your Fa...|129.85424|2001|ARSVTNL1187B992A91|\n",
      "|SOAFBCP12A8C13CC7D|King Of Scurf (20...|301.40036|1972|ARTC1LV1187B9A4858|\n",
      "|SORRNOC12AB017F52B|The Last Beat Of ...|337.81506|2004|ARSZ7L31187FB4E610|\n",
      "|SOQPWCR12A6D4FB2A3|A Poor Recipe For...|118.07302|2005|AR73AIO1187B9AD57B|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_df.printSchema()\n",
    "song_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## songplays_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplay_df = spark.read.parquet(output_data + 'songplays_table/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- user_agent: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|          start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|year|month|\n",
      "+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|2018-11-15 16:19:...|     97| paid|SOBLFFE12AF72AA5BA|ARJNIUY12298900C91|       605|Lansing-East Lans...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplay_df.printSchema()\n",
    "songplay_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## users_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "user_df = spark.read.parquet(output_data + 'users_table/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n",
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     88|  Mohammad|Rodriguez|     M| free|\n",
      "|     75|    Joseph|Gutierrez|     M| free|\n",
      "|     69|  Anabelle|  Simpson|     F| free|\n",
      "|     29|Jacqueline|    Lynch|     F| free|\n",
      "|     68|    Jordan|Rodriguez|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.printSchema()\n",
    "user_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## artists_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artist_df = spark.read.parquet(output_data + 'artists_table/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|         artist_id|         artist_name|            location|latitude|longitude|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|ARTC1LV1187B9A4858|  The Bonzo Dog Band|Goldsmith's Colle...| 51.4536| -0.01802|\n",
      "|ARA23XO1187B9AF18F|     The Smithereens|Carteret, New Jersey|40.57885|-74.21956|\n",
      "|ARSVTNL1187B992A91|       Jonathan King|     London, England|51.50632| -0.12714|\n",
      "|ARZ5H0P1187B98A1DD|          Snoop Dogg|      Long Beach, CA|33.76672|-118.1924|\n",
      "|ARXQBR11187B98A2CC|Frankie Goes To H...|  Liverpool, England|    null|     null|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_df.printSchema()\n",
    "artist_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## time_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_df = spark.read.parquet(output_data + 'time_table/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ts: long (nullable = true)\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+-------------+--------------------+----+---+----+-------+----+-----+\n",
      "|           ts|          start_time|hour|day|week|weekday|year|month|\n",
      "+-------------+--------------------+----+---+----+-------+----+-----+\n",
      "|1542299400796|2018-11-15 16:30:...|  16| 15|  46|      5|2018|   11|\n",
      "|1542302304796|2018-11-15 17:18:...|  17| 15|  46|      5|2018|   11|\n",
      "|1542313156796|2018-11-15 20:19:...|  20| 15|  46|      5|2018|   11|\n",
      "|1542318492796|2018-11-15 21:48:...|  21| 15|  46|      5|2018|   11|\n",
      "|1542828783796|2018-11-21 19:33:...|  19| 21|  47|      4|2018|   11|\n",
      "+-------------+--------------------+----+---+----+-------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_df.printSchema()\n",
    "time_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
