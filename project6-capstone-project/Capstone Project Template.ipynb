{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "**Tools:**\n",
    "- PySpark\n",
    "- AWS S3\n",
    "- AWS Redshift\n",
    "\n",
    "**Raw data using:**\n",
    "- Immigration data\n",
    "- Airport-code data\n",
    "- Cities demographics data\n",
    "- Global temperature (Don't use)\n",
    "\n",
    "\n",
    "**Pipeline:**\n",
    "\n",
    "![Pipeline](./images/pipeline.png)\n",
    "![AirFlow Pipeline](./images/airflow.png)\n",
    "\n",
    "```\n",
    "Fact Table: (us_immgration)\n",
    "    cic_id FLOAT,\n",
    "\ti94_year FLOAT,\n",
    "\ti94_mode FLOAT,\n",
    "\ti94_port VARCHAR,\n",
    "\ti94_age FLOAT,\n",
    "\tbirth_year FLOAT,\n",
    "\tgender VARCHAR(1),\n",
    "\ti94_address VARCHAR,\n",
    "\ti94_visa FLOAT,\n",
    "\tvisa_type VARCHAR,\n",
    "\tarrival_date DATE,\n",
    "\tdeparture_date VARCHAR,\n",
    "\tairport_name VARCHAR,\n",
    "\tstate_code VARCHAR,\n",
    "\tstate_name VARCHAR,\n",
    "\tairport_city VARCHAR,\n",
    "\ttotal_population INT,\n",
    "\tPRIMARY KEY (cic_id)\n",
    "```\n",
    "\n",
    "```\n",
    "Dim Table: (city_demographic)\n",
    "    city varchar,\n",
    "\t\"state\" varchar,\n",
    "\tmedian_age FLOAT,\n",
    "\tmale_population INT,\n",
    "\tfemale_population INT,\n",
    "\ttotal_Population INT,\n",
    "\tstate_code varchar,\n",
    "\tPRIMARY KEY (state_code)\n",
    "```\n",
    "\n",
    "```\n",
    "Dim Table: (airport)\n",
    "    ident varchar,\n",
    "\t\"type\" varchar,\n",
    "\t\"name\" varchar,\n",
    "\tcontinent varchar,\n",
    "\tiso_country varchar,\n",
    "\tmunicipality varchar,\n",
    "\tiata_code varchar,\n",
    "\t\"state\" varchar,\n",
    "\tPRIMARY KEY (iata_code)\n",
    "```\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when\n",
    "import pyspark.sql.functions as F\n",
    "import configparser\n",
    "from time import time\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id, year, month, dayofmonth, hour, weekofyear, date_format, dayofweek\n",
    "from pyspark.sql.types import TimestampType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Read Immigration sas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "Total Immigration records: \n",
      "3096313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5748522.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20579.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.498180e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5748523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20586.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497969e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5748524.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20586.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497975e+10</td>\n",
       "      <td>00010</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5748525.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.497325e+10</td>\n",
       "      <td>00028</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5748526.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>NZ</td>\n",
       "      <td>9.501355e+10</td>\n",
       "      <td>00002</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5748527.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20576.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>UA</td>\n",
       "      <td>9.493829e+10</td>\n",
       "      <td>01215</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5748528.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.501810e+10</td>\n",
       "      <td>00472</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5748529.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VA</td>\n",
       "      <td>20596.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.492490e+10</td>\n",
       "      <td>00488</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5748530.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.492648e+10</td>\n",
       "      <td>00302</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5748531.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.492629e+10</td>\n",
       "      <td>00302</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5748532.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>CM</td>\n",
       "      <td>9.500641e+10</td>\n",
       "      <td>00430</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5748534.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>CX</td>\n",
       "      <td>9.492476e+10</td>\n",
       "      <td>00872</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5748876.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20583.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>UA</td>\n",
       "      <td>9.499463e+10</td>\n",
       "      <td>05574</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5748877.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20583.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>UA</td>\n",
       "      <td>9.499448e+10</td>\n",
       "      <td>05574</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5748881.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>AM</td>\n",
       "      <td>9.496771e+10</td>\n",
       "      <td>00646</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0   5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1   5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2   5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3   5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4   5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "5   5748522.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "6   5748523.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "7   5748524.0  2016.0     4.0   245.0   464.0     HHW  20574.0      1.0   \n",
       "8   5748525.0  2016.0     4.0   245.0   464.0     HOU  20574.0      1.0   \n",
       "9   5748526.0  2016.0     4.0   245.0   464.0     LOS  20574.0      1.0   \n",
       "10  5748527.0  2016.0     4.0   245.0   504.0     NEW  20574.0      1.0   \n",
       "11  5748528.0  2016.0     4.0   245.0   504.0     LOS  20574.0      1.0   \n",
       "12  5748529.0  2016.0     4.0   245.0   504.0     WAS  20574.0      1.0   \n",
       "13  5748530.0  2016.0     4.0   245.0   504.0     LOS  20574.0      1.0   \n",
       "14  5748531.0  2016.0     4.0   245.0   504.0     LOS  20574.0      1.0   \n",
       "15  5748532.0  2016.0     4.0   245.0   504.0     MIA  20574.0      1.0   \n",
       "16  5748534.0  2016.0     4.0   245.0   528.0     SFR  20574.0      1.0   \n",
       "17  5748876.0  2016.0     4.0   245.0   582.0     HOU  20574.0      1.0   \n",
       "18  5748877.0  2016.0     4.0   245.0   582.0     HOU  20574.0      1.0   \n",
       "19  5748881.0  2016.0     4.0   245.0   582.0     LOS  20574.0      1.0   \n",
       "\n",
       "   i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0       CA  20582.0   ...        None        M   1976.0  10292016      F   \n",
       "1       NV  20591.0   ...        None        M   1984.0  10292016      F   \n",
       "2       WA  20582.0   ...        None        M   1987.0  10292016      M   \n",
       "3       WA  20588.0   ...        None        M   1987.0  10292016      F   \n",
       "4       WA  20588.0   ...        None        M   1988.0  10292016      M   \n",
       "5       HI  20579.0   ...        None        M   1959.0  10292016      M   \n",
       "6       HI  20586.0   ...        None        M   1950.0  10292016      F   \n",
       "7       HI  20586.0   ...        None        M   1975.0  10292016      F   \n",
       "8       FL  20581.0   ...        None        M   1989.0  10292016      M   \n",
       "9       CA  20581.0   ...        None        M   1990.0  10292016      F   \n",
       "10      MA  20576.0   ...        None        M   1972.0  10292016      M   \n",
       "11    None  20575.0   ...        None        M   1977.0  10292016      M   \n",
       "12      VA  20596.0   ...        None        M   1978.0  10292016      M   \n",
       "13      CA  20577.0   ...        None        M   1960.0  10292016      F   \n",
       "14      CA  20577.0   ...        None        M   1978.0  10282016      M   \n",
       "15      FL  20581.0   ...        None        M   1963.0  10292016      F   \n",
       "16      CA      NaN   ...        None     None   1932.0  10282016      F   \n",
       "17      TX  20583.0   ...        None        M   1973.0  10292016      M   \n",
       "18      TX  20583.0   ...        None        M   1986.0  10292016      F   \n",
       "19      CA  20575.0   ...        None        M   1982.0  10292016      M   \n",
       "\n",
       "   insnum airline        admnum  fltno visatype  \n",
       "0    None      QF  9.495387e+10  00011       B1  \n",
       "1    None      VA  9.495562e+10  00007       B1  \n",
       "2    None      DL  9.495641e+10  00040       B1  \n",
       "3    None      DL  9.495645e+10  00040       B1  \n",
       "4    None      DL  9.495639e+10  00040       B1  \n",
       "5    None      NZ  9.498180e+10  00010       B2  \n",
       "6    None      NZ  9.497969e+10  00010       B2  \n",
       "7    None      NZ  9.497975e+10  00010       B2  \n",
       "8    None      NZ  9.497325e+10  00028       B2  \n",
       "9    None      NZ  9.501355e+10  00002       B2  \n",
       "10   None      UA  9.493829e+10  01215       B2  \n",
       "11   None      CM  9.501810e+10  00472       B2  \n",
       "12   None      CM  9.492490e+10  00488       B2  \n",
       "13   None      CM  9.492648e+10  00302       B2  \n",
       "14   None      CM  9.492629e+10  00302       B2  \n",
       "15   None      CM  9.500641e+10  00430       B2  \n",
       "16   None      CX  9.492476e+10  00872       B2  \n",
       "17   None      UA  9.499463e+10  05574       B1  \n",
       "18   None      UA  9.499448e+10  05574       B1  \n",
       "19   None      AM  9.496771e+10  00646       B2  \n",
       "\n",
       "[20 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_imm=spark.read.parquet(\"sas_data\")\n",
    "df_imm.printSchema()\n",
    "print('Total Immigration records: ')\n",
    "print(df_imm.count())\n",
    "df_imm.limit(20).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Read airport csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport = spark.read.csv('./airport-codes_csv.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "Total airport records: \n",
      "55075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>iata_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00CA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldstone /Gts/ Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Barstow</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00CL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Williams Ag Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00CN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Kitchen Creek Helibase Heliport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00CO</td>\n",
       "      <td>closed</td>\n",
       "      <td>Cass Field</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Briggsdale</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Grass Patch Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Bushnell</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00FD</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Ringhaver Heliport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Riverview</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00FL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>River Oak Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Okeechobee</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00GA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lt World Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-GA</td>\n",
       "      <td>Lithonia</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00GE</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Caffrey Heliport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-GA</td>\n",
       "      <td>Hiram</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00HI</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Kaupulehu Heliport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-HI</td>\n",
       "      <td>Kailua/Kona</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00ID</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Delta Shores Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-ID</td>\n",
       "      <td>Clark Fork</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00IG</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goltl Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>McDonald</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00II</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Bailey Generation Station Heliport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IN</td>\n",
       "      <td>Chesterton</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ident           type                                name continent  \\\n",
       "0    00A       heliport                   Total Rf Heliport        NA   \n",
       "1   00AA  small_airport                Aero B Ranch Airport        NA   \n",
       "2   00AK  small_airport                        Lowell Field        NA   \n",
       "3   00AL  small_airport                        Epps Airpark        NA   \n",
       "4   00AR         closed  Newport Hospital & Clinic Heliport        NA   \n",
       "5   00AS  small_airport                      Fulton Airport        NA   \n",
       "6   00AZ  small_airport                      Cordes Airport        NA   \n",
       "7   00CA  small_airport             Goldstone /Gts/ Airport        NA   \n",
       "8   00CL  small_airport                 Williams Ag Airport        NA   \n",
       "9   00CN       heliport     Kitchen Creek Helibase Heliport        NA   \n",
       "10  00CO         closed                          Cass Field        NA   \n",
       "11  00FA  small_airport                 Grass Patch Airport        NA   \n",
       "12  00FD       heliport                  Ringhaver Heliport        NA   \n",
       "13  00FL  small_airport                   River Oak Airport        NA   \n",
       "14  00GA  small_airport                    Lt World Airport        NA   \n",
       "15  00GE       heliport                    Caffrey Heliport        NA   \n",
       "16  00HI       heliport                  Kaupulehu Heliport        NA   \n",
       "17  00ID  small_airport                Delta Shores Airport        NA   \n",
       "18  00IG  small_airport                       Goltl Airport        NA   \n",
       "19  00II       heliport  Bailey Generation Station Heliport        NA   \n",
       "\n",
       "   iso_country iso_region  municipality iata_code  \n",
       "0           US      US-PA      Bensalem      None  \n",
       "1           US      US-KS         Leoti      None  \n",
       "2           US      US-AK  Anchor Point      None  \n",
       "3           US      US-AL       Harvest      None  \n",
       "4           US      US-AR       Newport      None  \n",
       "5           US      US-OK          Alex      None  \n",
       "6           US      US-AZ        Cordes      None  \n",
       "7           US      US-CA       Barstow      None  \n",
       "8           US      US-CA         Biggs      None  \n",
       "9           US      US-CA   Pine Valley      None  \n",
       "10          US      US-CO    Briggsdale      None  \n",
       "11          US      US-FL      Bushnell      None  \n",
       "12          US      US-FL     Riverview      None  \n",
       "13          US      US-FL    Okeechobee      None  \n",
       "14          US      US-GA      Lithonia      None  \n",
       "15          US      US-GA         Hiram      None  \n",
       "16          US      US-HI   Kailua/Kona      None  \n",
       "17          US      US-ID    Clark Fork      None  \n",
       "18          US      US-KS      McDonald      None  \n",
       "19          US      US-IN    Chesterton      None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.printSchema()\n",
    "print('Total airport records: ')\n",
    "print(df_airport.count())\n",
    "df_airport = df_airport.drop('local_code', 'coordinates', 'gps_code', 'elevation_ft')\n",
    "df_airport.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Read us-cities demographics csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_city = spark.read.csv('./us-cities-demographics.csv', header=True, inferSchema=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- male_population: integer (nullable = true)\n",
      " |-- female_population: integer (nullable = true)\n",
      " |-- total_Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n",
      "Total us-cities records: \n",
      "2891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_Population</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56229</td>\n",
       "      <td>62432</td>\n",
       "      <td>118661</td>\n",
       "      <td>IL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avondale</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>29.1</td>\n",
       "      <td>38712</td>\n",
       "      <td>41971</td>\n",
       "      <td>80683</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Black or African-American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Covina</td>\n",
       "      <td>California</td>\n",
       "      <td>39.8</td>\n",
       "      <td>51629</td>\n",
       "      <td>56860</td>\n",
       "      <td>108489</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41762</td>\n",
       "      <td>43270</td>\n",
       "      <td>85032</td>\n",
       "      <td>MO</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High Point</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>51751</td>\n",
       "      <td>58077</td>\n",
       "      <td>109828</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Folsom</td>\n",
       "      <td>California</td>\n",
       "      <td>40.9</td>\n",
       "      <td>41051</td>\n",
       "      <td>35317</td>\n",
       "      <td>76368</td>\n",
       "      <td>CA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Folsom</td>\n",
       "      <td>California</td>\n",
       "      <td>40.9</td>\n",
       "      <td>41051</td>\n",
       "      <td>35317</td>\n",
       "      <td>76368</td>\n",
       "      <td>CA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>34.1</td>\n",
       "      <td>741270</td>\n",
       "      <td>826172</td>\n",
       "      <td>1567442</td>\n",
       "      <td>PA</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wichita</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>34.6</td>\n",
       "      <td>192354</td>\n",
       "      <td>197601</td>\n",
       "      <td>389955</td>\n",
       "      <td>KS</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wichita</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>34.6</td>\n",
       "      <td>192354</td>\n",
       "      <td>197601</td>\n",
       "      <td>389955</td>\n",
       "      <td>KS</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>Florida</td>\n",
       "      <td>37.3</td>\n",
       "      <td>36850</td>\n",
       "      <td>37165</td>\n",
       "      <td>74015</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>32.9</td>\n",
       "      <td>149690</td>\n",
       "      <td>154695</td>\n",
       "      <td>304385</td>\n",
       "      <td>PA</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Laredo</td>\n",
       "      <td>Texas</td>\n",
       "      <td>28.8</td>\n",
       "      <td>124305</td>\n",
       "      <td>131484</td>\n",
       "      <td>255789</td>\n",
       "      <td>TX</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Berkeley</td>\n",
       "      <td>California</td>\n",
       "      <td>32.5</td>\n",
       "      <td>60142</td>\n",
       "      <td>60829</td>\n",
       "      <td>120971</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>California</td>\n",
       "      <td>35.2</td>\n",
       "      <td>63278</td>\n",
       "      <td>62938</td>\n",
       "      <td>126216</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                city           state  median_age  male_population  \\\n",
       "0      Silver Spring        Maryland        33.8            40601   \n",
       "1             Quincy   Massachusetts        41.0            44129   \n",
       "2             Hoover         Alabama        38.5            38040   \n",
       "3   Rancho Cucamonga      California        34.5            88127   \n",
       "4             Newark      New Jersey        34.6           138040   \n",
       "5             Peoria        Illinois        33.1            56229   \n",
       "6           Avondale         Arizona        29.1            38712   \n",
       "7        West Covina      California        39.8            51629   \n",
       "8           O'Fallon        Missouri        36.0            41762   \n",
       "9         High Point  North Carolina        35.5            51751   \n",
       "10            Folsom      California        40.9            41051   \n",
       "11            Folsom      California        40.9            41051   \n",
       "12      Philadelphia    Pennsylvania        34.1           741270   \n",
       "13           Wichita          Kansas        34.6           192354   \n",
       "14           Wichita          Kansas        34.6           192354   \n",
       "15        Fort Myers         Florida        37.3            36850   \n",
       "16        Pittsburgh    Pennsylvania        32.9           149690   \n",
       "17            Laredo           Texas        28.8           124305   \n",
       "18          Berkeley      California        32.5            60142   \n",
       "19       Santa Clara      California        35.2            63278   \n",
       "\n",
       "    female_population  total_Population state_code  \\\n",
       "0               41862             82463         MD   \n",
       "1               49500             93629         MA   \n",
       "2               46799             84839         AL   \n",
       "3               87105            175232         CA   \n",
       "4              143873            281913         NJ   \n",
       "5               62432            118661         IL   \n",
       "6               41971             80683         AZ   \n",
       "7               56860            108489         CA   \n",
       "8               43270             85032         MO   \n",
       "9               58077            109828         NC   \n",
       "10              35317             76368         CA   \n",
       "11              35317             76368         CA   \n",
       "12             826172           1567442         PA   \n",
       "13             197601            389955         KS   \n",
       "14             197601            389955         KS   \n",
       "15              37165             74015         FL   \n",
       "16             154695            304385         PA   \n",
       "17             131484            255789         TX   \n",
       "18              60829            120971         CA   \n",
       "19              62938            126216         CA   \n",
       "\n",
       "                                 race  \n",
       "0                  Hispanic or Latino  \n",
       "1                               White  \n",
       "2                               Asian  \n",
       "3           Black or African-American  \n",
       "4                               White  \n",
       "5   American Indian and Alaska Native  \n",
       "6           Black or African-American  \n",
       "7                               Asian  \n",
       "8                  Hispanic or Latino  \n",
       "9                               Asian  \n",
       "10                 Hispanic or Latino  \n",
       "11  American Indian and Alaska Native  \n",
       "12                              Asian  \n",
       "13                 Hispanic or Latino  \n",
       "14  American Indian and Alaska Native  \n",
       "15                              White  \n",
       "16                              White  \n",
       "17  American Indian and Alaska Native  \n",
       "18                              Asian  \n",
       "19                              White  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city = df_city.withColumnRenamed('City', 'city').withColumnRenamed('State', 'state').withColumnRenamed('Median Age', 'median_age') \\\n",
    ".withColumnRenamed('Male Population', 'male_population').withColumnRenamed('Female Population', 'female_population') \\\n",
    ".withColumnRenamed('Total Population', 'total_Population').withColumnRenamed('State Code', 'state_code').withColumnRenamed('Race', 'race')\n",
    "df_city.printSchema()\n",
    "print('Total us-cities records: ')\n",
    "print(df_city.count())\n",
    "city_columns = ['city', 'state', 'median_age', 'male_population', 'female_population', 'total_Population', 'state_code', 'race']\n",
    "df_city = df_city.select([col for col in city_columns])\n",
    "df_city.limit(20).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Read World Temperature csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp = spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n",
      "Total Temperature records: \n",
      "8599212\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "0 1820-01-01               2.101                          3.217  Abilene   \n",
       "1 1820-02-01               6.926                          2.853  Abilene   \n",
       "2 1820-03-01              10.767                          2.395  Abilene   \n",
       "3 1820-04-01              17.989                          2.202  Abilene   \n",
       "4 1820-05-01              21.809                          2.036  Abilene   \n",
       "\n",
       "         Country Latitude Longitude  \n",
       "0  United States   32.95N   100.53W  \n",
       "1  United States   32.95N   100.53W  \n",
       "2  United States   32.95N   100.53W  \n",
       "3  United States   32.95N   100.53W  \n",
       "4  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.printSchema()\n",
    "print('Total Temperature records: ')\n",
    "print(df_temp.count())\n",
    "df_temp.filter(\"Country = 'United States'\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def count_null_column(spark_df):\n",
    "    print('Total rows: ' + str(spark_df.count()))\n",
    "    print('=== Count null value of each column ===')\n",
    "    for column in spark_df.columns:\n",
    "        print(column + ': ' + str(spark_df.filter(\"{} is NULL\".format(column)).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1 Airport data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 55075\n",
      "=== Count null value of each column ===\n",
      "ident: 0\n",
      "type: 0\n",
      "name: 0\n",
      "continent: 0\n",
      "iso_country: 0\n",
      "iso_region: 0\n",
      "municipality: 5676\n",
      "iata_code: 45886\n"
     ]
    }
   ],
   "source": [
    "count_null_column(df_airport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "=> [iata_code] coulmn have 45886 null value -> 45886/55075(Total record) = 83,3% => 83,3% of this Airport data is missing value for [iata_code] => **Solution 1:  remove null value of [iata_code] column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total airport records before: \n",
      "55075\n",
      "Total airport records after: \n",
      "9189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>iata_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03N</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Utirik Airport</td>\n",
       "      <td>OC</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH-UTI</td>\n",
       "      <td>Utirik Island</td>\n",
       "      <td>UTK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>OCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Pilot Station</td>\n",
       "      <td>PQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0CO2</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Crested Butte</td>\n",
       "      <td>CSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0TE7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Johnson City</td>\n",
       "      <td>JCY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                     name continent iso_country  \\\n",
       "0   03N  small_airport           Utirik Airport        OC          MH   \n",
       "1  07FA  small_airport  Ocean Reef Club Airport        NA          US   \n",
       "2   0AK  small_airport    Pilot Station Airport        NA          US   \n",
       "3  0CO2  small_airport    Crested Butte Airpark        NA          US   \n",
       "4  0TE7  small_airport        LBJ Ranch Airport        NA          US   \n",
       "\n",
       "  iso_region   municipality iata_code  \n",
       "0     MH-UTI  Utirik Island       UTK  \n",
       "1      US-FL      Key Largo       OCA  \n",
       "2      US-AK  Pilot Station       PQS  \n",
       "3      US-CO  Crested Butte       CSE  \n",
       "4      US-TX   Johnson City       JCY  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 1: remove null value of [iata_code] column\n",
    "print('Total airport records before: ')\n",
    "print(df_airport.count())\n",
    "df_airport = df_airport.dropna(how='any',subset='iata_code') # remove iata_code column\n",
    "print('Total airport records after: ')\n",
    "print(df_airport.count())\n",
    "df_airport.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport.createOrReplaceTempView(\"air_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 2: Select only US airport\n",
    "df_airport = spark.sql(\"\"\"SELECT *\n",
    "                FROM air_table WHERE LEFT(iso_region, 2) = 'US'\"\"\")\n",
    "df_airport.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport.createOrReplaceTempView(\"air_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Solution 3: Convert iso_region to US state\n",
    "df_airport = spark.sql(\"\"\"SELECT *, SUBSTRING (iso_region, 4) as state\n",
    "                FROM air_table\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+---------+-----------+-------------+---------+-----+\n",
      "|ident|         type|                name|continent|iso_country| municipality|iata_code|state|\n",
      "+-----+-------------+--------------------+---------+-----------+-------------+---------+-----+\n",
      "| 07FA|small_airport|Ocean Reef Club A...|       NA|         US|    Key Largo|      OCA|   FL|\n",
      "|  0AK|small_airport|Pilot Station Air...|       NA|         US|Pilot Station|      PQS|   AK|\n",
      "| 0CO2|small_airport|Crested Butte Air...|       NA|         US|Crested Butte|      CSE|   CO|\n",
      "| 0TE7|small_airport|   LBJ Ranch Airport|       NA|         US| Johnson City|      JCY|   TX|\n",
      "| 13MA|small_airport|Metropolitan Airport|       NA|         US|       Palmer|      PMX|   MA|\n",
      "+-----+-------------+--------------------+---------+-----------+-------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport = df_airport.drop('iso_region')\n",
    "df_airport.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport.createOrReplaceTempView(\"air_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+\n",
      "|iata_code|                name|count|\n",
      "+---------+--------------------+-----+\n",
      "|      AHT|Amchitka Army Air...|    2|\n",
      "+---------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT iata_code, name, COUNT (name) as count\n",
    "FROM air_table\n",
    "GROUP BY iata_code, name\n",
    "HAVING COUNT > 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are some duplicated rows in Airport data => **Solution 2: drop some duplicated value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total airport records before: \n",
      "2019\n",
      "Total records after dropping duplicates: \n",
      "2006\n"
     ]
    }
   ],
   "source": [
    "# Solution 4: drop some duplicated value\n",
    "print('Total airport records before: ')\n",
    "print(df_airport.count())\n",
    "df_airport = df_airport.dropDuplicates([\"name\"])\n",
    "print('Total records after dropping duplicates: ')\n",
    "print(df_airport.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check no duplicated values in airport table\n",
    "df_airport.createOrReplaceTempView(\"air_table_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----+\n",
      "|iata_code|name|count|\n",
      "+---------+----+-----+\n",
      "+---------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT iata_code, name, COUNT (name) as count\n",
    "FROM air_table_final\n",
    "GROUP BY iata_code, name\n",
    "HAVING COUNT > 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+--------------------+---------+-----------+------------+---------+-----+\n",
      "|ident|          type|                name|continent|iso_country|municipality|iata_code|state|\n",
      "+-----+--------------+--------------------+---------+-----------+------------+---------+-----+\n",
      "| PAGQ| small_airport|    Big Lake Airport|       NA|         US|    Big Lake|      BGQ|   AK|\n",
      "| KBNO|medium_airport|Burns Municipal A...|       NA|         US|       Burns|      BNO|   OR|\n",
      "| PAFV| small_airport|   Five Mile Airport|       NA|         US|   Five Mile|      FMC|   AK|\n",
      "| KFTW| large_airport|Fort Worth Meacha...|       NA|         US|  Fort Worth|      FTW|   TX|\n",
      "|  FEW|      heliport|Francis E Warren ...|       NA|         US|    Cheyenne|      FEW|   WY|\n",
      "+-----+--------------+--------------------+---------+-----------+------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport.show(5)\n",
    "df_airport.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Conclusion In Raw airport data: there 4 solutions to clean data:\n",
    "- Solution 1: remove null value of [iata_code] column\n",
    "- Solution 2: Select only US airport\n",
    "- Solution 3: Convert iso_region to US state\n",
    "- Solution 4: drop some duplicated value\n",
    "\n",
    "final Airport Data Frame: df_airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2 Us-cities demographics data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 2891\n",
      "=== Count null value of each column ===\n",
      "city: 0\n",
      "state: 0\n",
      "median_age: 0\n",
      "male_population: 3\n",
      "female_population: 3\n",
      "total_Population: 0\n",
      "state_code: 0\n",
      "race: 0\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+----------+------------------+\n",
      "|         city|        state|median_age|male_population|female_population|total_Population|state_code|              race|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+----------+------------------+\n",
      "|Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|        MD|Hispanic or Latino|\n",
      "|       Quincy|Massachusetts|      41.0|          44129|            49500|           93629|        MA|             White|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_null_column(df_city)\n",
    "df_city.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are 3 records with Null value for male_population and female_population\n",
    "\n",
    "try to figure out these 3 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_city.createOrReplaceTempView(\"city_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+----------+---------------+-----------------+----------------+----------+--------------------+\n",
      "|        city|  state|median_age|male_population|female_population|total_Population|state_code|                race|\n",
      "+------------+-------+----------+---------------+-----------------+----------------+----------+--------------------+\n",
      "|The Villages|Florida|      70.5|           null|             null|           72590|        FL|  Hispanic or Latino|\n",
      "|The Villages|Florida|      70.5|           null|             null|           72590|        FL|Black or African-...|\n",
      "|The Villages|Florida|      70.5|           null|             null|           72590|        FL|               White|\n",
      "+------------+-------+----------+---------------+-----------------+----------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM city_table\n",
    "where male_population is NULL OR female_population is Null OR (male_population is NULL AND female_population is Null)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The Village city in Florida have total_Population = 72590 included 3 race as above table => there are duplicated value => **Solution 2: Remove [race] column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_Population</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city          state  median_age  male_population  \\\n",
       "0  Silver Spring       Maryland        33.8            40601   \n",
       "1         Quincy  Massachusetts        41.0            44129   \n",
       "\n",
       "   female_population  total_Population state_code  \n",
       "0              41862             82463         MD  \n",
       "1              49500             93629         MA  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Solution 2.1: Remove [race] column\n",
    "city_columns = ['city', 'state', 'median_age', 'male_population', 'female_population', 'total_Population', 'state_code']\n",
    "df_city = df_city.select([col for col in city_columns])\n",
    "df_city.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_city.createOrReplaceTempView(\"city_table2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+---------------+-----------------+----------------+----------+-----+\n",
      "|      city|     state|median_age|male_population|female_population|total_Population|state_code|count|\n",
      "+----------+----------+----------+---------------+-----------------+----------------+----------+-----+\n",
      "|     Bryan|     Texas|      29.4|          41761|            40345|           82106|        TX|    5|\n",
      "|Fort Smith|  Arkansas|      34.9|          43346|            44849|           88195|        AR|    5|\n",
      "|   Houston|     Texas|      32.6|        1149686|          1148942|         2298628|        TX|    5|\n",
      "|   Phoenix|   Arizona|      33.8|         786833|           776168|         1563001|        AZ|    5|\n",
      "|    Pomona|California|      32.1|          74945|            78307|          153252|        CA|    5|\n",
      "+----------+----------+----------+---------------+-----------------+----------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+-----------+----------+---------------+-----------------+----------------+----------+-----+\n",
      "|   city|      state|median_age|male_population|female_population|total_Population|state_code|count|\n",
      "+-------+-----------+----------+---------------+-----------------+----------------+----------+-----+\n",
      "|BayamÃ³n|Puerto Rico|      39.4|          80128|            90131|          170259|        PR|    1|\n",
      "|  Ponce|Puerto Rico|      40.5|          56968|            64615|          121583|        PR|    1|\n",
      "+-------+-----------+----------+---------------+-----------------+----------------+----------+-----+\n",
      "\n",
      "+--------------------+\n",
      "|total_distinct_value|\n",
      "+--------------------+\n",
      "|                   2|\n",
      "+--------------------+\n",
      "\n",
      "+----------------------+\n",
      "|total_duplicated_value|\n",
      "+----------------------+\n",
      "|                   594|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT city, state, median_age, male_population, female_population, total_Population, state_code, count(*) as count\n",
    "FROM city_table2\n",
    "GROUP BY city, state, median_age, male_population, female_population, total_Population, state_code\n",
    "HAVING COUNT >1\n",
    "\"\"\").createOrReplaceTempView(\"temp1\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT city, state, median_age, male_population, female_population, total_Population, state_code, count(*) as count\n",
    "FROM city_table2\n",
    "GROUP BY city, state, median_age, male_population, female_population, total_Population, state_code\n",
    "HAVING COUNT = 1\n",
    "\"\"\").createOrReplaceTempView(\"temp2\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT * FROM temp1\n",
    "\"\"\").show(5)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT * FROM temp2\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(*) as total_distinct_value from temp2\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT count(*) as total_duplicated_value from temp1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We got 594 total_duplicated_value and 2 total_distinct_value => 594 + 2 = 596 distinct records => **Solution 3: drop duplicated values and expected total distinct records = 596**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total demographics records before: \n",
      "2891\n",
      "Total records after dropping duplicates: \n",
      "596\n"
     ]
    }
   ],
   "source": [
    "#  Solution 3: drop duplicated values and expected total distinct records = 596\n",
    "print('Total demographics records before: ')\n",
    "print(df_city.count())\n",
    "df_city = df_city.dropDuplicates(city_columns)\n",
    "print('Total records after dropping duplicates: ')\n",
    "print(df_city.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- male_population: integer (nullable = true)\n",
      " |-- female_population: integer (nullable = true)\n",
      " |-- total_Population: integer (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_city.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Conclusion In Raw demographics  data: there 3 solution to clean data:\n",
    "- Solution 1: Filter Country = United States only\n",
    "- Solution 2: remove some unused column, included [race] column\n",
    "- Solution 3: drop duplicated values => 596 records in total\n",
    "\n",
    "final demographics Data Frame: df_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.3 Global temperature data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01 00:00:00|             6.068|           1.7369999999999999|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01 00:00:00|              null|                         null|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01 00:00:00|              null|                         null|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|            min(dt)|            max(dt)|\n",
      "+-------------------+-------------------+\n",
      "|1743-11-01 00:00:00|2013-09-01 00:00:00|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define min time and max time of dataset\n",
    "df_temp.agg(F.min(\"dt\"), F.max(\"dt\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " max year in temperature dataset is 2013=> No temperature data available for immigration dataset (2016 only)\n",
    " \n",
    " **=>I dont use this dataset for my capstone project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.4 Immigration data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imm.show(2)\n",
    "df_imm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_imm.createOrReplaceTempView(\"imm_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Solution 1:convert arrdate, depdate to datetime, create column name arrival_date and departure_date\n",
    "spark.sql(\"SELECT *, date_add(to_date('1960-01-01'), arrdate) AS arrival_date FROM imm_table\").createOrReplaceTempView(\"imm_table\")\n",
    "df_imm = spark.sql(\"\"\"SELECT *, CASE \n",
    "                        WHEN depdate >= 1.0 THEN date_add(to_date('1960-01-01'), depdate)\n",
    "                        WHEN depdate IS NULL THEN NULL\n",
    "                        ELSE 'N/A' END AS departure_date \n",
    "                FROM imm_table\"\"\")\n",
    "df_imm.createOrReplaceTempView(\"imm_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|arrival_date|departure_date|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|  2016-04-30|    2016-05-08|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|  2016-04-30|    2016-05-17|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|  2016-04-30|    2016-05-08|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_imm.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>i94_year</th>\n",
       "      <th>i94_mode</th>\n",
       "      <th>i94_port</th>\n",
       "      <th>i94_age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>i94_address</th>\n",
       "      <th>i94_visa</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>F</td>\n",
       "      <td>CA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>M</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>F</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>M</td>\n",
       "      <td>WA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cic_id  i94_year  i94_mode i94_port  i94_age  birth_year gender  \\\n",
       "0  5748517.0    2016.0       1.0      LOS     40.0      1976.0      F   \n",
       "1  5748518.0    2016.0       1.0      LOS     32.0      1984.0      F   \n",
       "2  5748519.0    2016.0       1.0      LOS     29.0      1987.0      M   \n",
       "3  5748520.0    2016.0       1.0      LOS     29.0      1987.0      F   \n",
       "4  5748521.0    2016.0       1.0      LOS     28.0      1988.0      M   \n",
       "\n",
       "  i94_address  i94_visa visa_type arrival_date departure_date  \n",
       "0          CA       1.0        B1   2016-04-30     2016-05-08  \n",
       "1          NV       1.0        B1   2016-04-30     2016-05-17  \n",
       "2          WA       1.0        B1   2016-04-30     2016-05-08  \n",
       "3          WA       1.0        B1   2016-04-30     2016-05-14  \n",
       "4          WA       1.0        B1   2016-04-30     2016-05-14  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 2: remove unused column\n",
    "df_imm = df_imm.withColumnRenamed('cicid', 'cic_id').withColumnRenamed('i94yr', 'i94_year').withColumnRenamed('i94mode', 'i94_mode').withColumnRenamed('i94port', 'i94_port') \\\n",
    ".withColumnRenamed('i94addr', 'i94_address').withColumnRenamed('i94bir', 'i94_age').withColumnRenamed('biryear', 'birth_year') \\\n",
    ".withColumnRenamed('i94visa', 'i94_visa').withColumnRenamed('visatype', 'visa_type')\n",
    "imm_columns = ['cic_id', 'i94_year', 'i94_mode', 'i94_port', 'i94_age', 'birth_year', 'gender', 'i94_address', 'i94_visa', 'visa_type', 'arrival_date', 'departure_date']\n",
    "df_imm = df_imm.select([col for col in imm_columns])\n",
    "df_imm.limit(5).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2953481"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 3: Ensure that departure_date >= arrival_date\n",
    "df_imm = df_imm.filter(\"departure_date >= arrival_date\")\n",
    "df_imm.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For i94mode defination \n",
    "1 = 'Air'\n",
    "2 = 'Sea'\n",
    "3 = 'Land'\n",
    "9 = 'Not reported'\n",
    "=> **Filter Air only to map with Airport data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_imm = df_imm.filter(\"i94_mode == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cic_id: double (nullable = true)\n",
      " |-- i94_year: double (nullable = true)\n",
      " |-- i94_mode: double (nullable = true)\n",
      " |-- i94_port: string (nullable = true)\n",
      " |-- i94_age: double (nullable = true)\n",
      " |-- birth_year: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- i94_address: string (nullable = true)\n",
      " |-- i94_visa: double (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2871184"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imm.printSchema()\n",
    "df_imm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_imm.createOrReplaceTempView(\"imm_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|gender|  count|\n",
      "+------+-------+\n",
      "|     F|1190456|\n",
      "|  null| 405106|\n",
      "|     M|1274898|\n",
      "|     U|     13|\n",
      "|     X|    711|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT gender, count(*) as count\n",
    "FROM imm_table\n",
    "GROUP BY gender\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Solution 4: Keep only Male and Female gender\n",
    "df_imm = df_imm.filter(\"gender in('M', 'F')\").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2465354\n",
      "+------+--------+--------+--------+-------+----------+------+-----------+--------+---------+------------+--------------+\n",
      "|cic_id|i94_year|i94_mode|i94_port|i94_age|birth_year|gender|i94_address|i94_visa|visa_type|arrival_date|departure_date|\n",
      "+------+--------+--------+--------+-------+----------+------+-----------+--------+---------+------------+--------------+\n",
      "| 206.0|  2016.0|     1.0|     NYC|   27.0|    1989.0|     M|         CO|     2.0|       WT|  2016-04-01|    2016-04-09|\n",
      "| 358.0|  2016.0|     1.0|     ORL|   36.0|    1980.0|     M|         FL|     2.0|       WT|  2016-04-01|    2016-04-17|\n",
      "| 529.0|  2016.0|     1.0|     PHI|   30.0|    1986.0|     M|         NV|     2.0|       WT|  2016-04-01|    2016-04-08|\n",
      "+------+--------+--------+--------+-------+----------+------+-----------+--------+---------+------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- cic_id: double (nullable = true)\n",
      " |-- i94_year: double (nullable = true)\n",
      " |-- i94_mode: double (nullable = true)\n",
      " |-- i94_port: string (nullable = true)\n",
      " |-- i94_age: double (nullable = true)\n",
      " |-- birth_year: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- i94_address: string (nullable = true)\n",
      " |-- i94_visa: double (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_imm.count())\n",
    "df_imm.show(3)\n",
    "df_imm.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Conclusion Immigration data: there 4 solutions to clean data:\n",
    "- Solution 1: convert arrdate, depdate to datetime, create column name arrival_date and departure_date\n",
    "- Solution 2: remove unused column\n",
    "- Solution 3: Ensure that departure_date >= arrival_date\n",
    "- Solution 4: Keep only Male and Female gender\n",
    "\n",
    "final Immigration Data Frame: df_imm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "please check at exploration step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Upload to Staging S3\n",
    "\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config_file_path = 'dwh_p.cfg'\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open(config_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKIATG7HQRUYE6T2DXEF\n",
      "vdLGc2XA/K3zK9dxZj2NADD9BC1VvVKk8F599fR4\n"
     ]
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = config.get('AWS', 'key')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config.get('AWS', 'secret')\n",
    "S3_BUCKET_OUTPUT = config.get(\"S3\", \"S3_BUCKET_OUTPUT\")\n",
    "output_data = \"s3a://{}/\".format(S3_BUCKET_OUTPUT)\n",
    "\n",
    "print(os.environ['AWS_ACCESS_KEY_ID'])\n",
    "print(os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_imm.limit(40).write.mode('overwrite').parquet('output_data_workspace/df_imm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport.limit(40).write.mode('overwrite').parquet('output_data_workspace/df_airport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_city.limit(40).write.mode('overwrite').parquet('output_data_workspace/df_city')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "![Pipeline](./images/pipeline.png)\n",
    "\n",
    "1. Create/use IAM user with attach policy ```AdministratorAccess```, ```AmazonRedshiftFullAccess```, ```AmazonS3FullAccess```\n",
    "2. Modify that Aws_access_key and aws_secret_key to ```dwh_p.cfg``` file\n",
    "3. Run ```python aws_helper/create_cluster.py``` to create Redshift cluster (~ 3 mins wait)\n",
    "4. Run ```python aws_helper/create_s3.py``` to create S3 bucket\n",
    "5. In  ```dwh_p.cfg``` file will autofill redshift cluster host name: (or capture host name from log):\n",
    "6. Read and Run ```CapstoneProject Template.ipynb``` to explore and clean data\n",
    "7. Start airflow UI: ```/opt/airflow/start.sh``` then click ```Access Airflow``` button\n",
    "8. Config redshift aws credential manually\n",
    "9. Run airflow dag file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clearly state the rationale for the choice of tools and technologies for the project.**\n",
    "Based on Project 4 and Project 5 in Udacity I decided to apply Data lake and Data Pipeline to practice DE course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propose how often the data should be updated and why.**\n",
    "immigration data will be updated monthly as current behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data was increased by 100x.**\n",
    "PySpark can handle these data and AWS redshift can increase the number of nodes to improve the speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data populates a dashboard that must be updated on a daily basis by 7am every day.**\n",
    "AirFlow pipeline can help that with scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The database needed to be accessed by 100+ people.**\n",
    "https://docs.aws.amazon.com/redshift/latest/mgmt/amazon-redshift-limits.html\n",
    "Maximum number of connections that you can create using the query editor v2 in this account in the current Region is 500\n",
    "So AWS Redshift can help with this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
